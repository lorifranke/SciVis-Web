                                                                      Graphical Models 104 (2019) 101036


                                                                   Contents lists available at ScienceDirect


                                                                        Graphical Models
                                                           journal homepage: www.elsevier.com/locate/gmod




Concepts and techniques for web-based visualization and processing of
massive 3D point clouds with semantics
Sören Discher∗, Rico Richter, Jürgen Döllner
Hasso Plattner Institute, University of Potsdam, Germany




a r t i c l e           i n f o                            a b s t r a c t

Keywords:                                                  3D point cloud technology facilitates the automated and highly detailed acquisition of real-world environments
3D Point clouds                                            such as assets, sites, and countries. We present a web-based system for the interactive exploration and inspection
Web-based rendering                                        of arbitrary large 3D point clouds. Our approach is able to render 3D point clouds with billions of points using
Point-based rendering
                                                           spatial data structures and level-of-detail representations. Point-based rendering techniques and post-processing
Processing strategies
                                                           eﬀects are provided to enable task-speciﬁc and data-speciﬁc ﬁltering, e.g., based on semantics. A set of interac-
                                                           tion techniques allows users to collaboratively work with the data (e.g., measuring distances and annotating).
                                                           Additional value is provided by the system’s ability to display additional, context-providing geodata alongside
                                                           3D point clouds and to integrate processing and analysis operations. We have evaluated the presented techniques
                                                           and in case studies and with diﬀerent data sets from aerial, mobile, and terrestrial acquisition with up to 120
                                                           billion points to show their practicality and feasibility.



1. Motivation                                                                               ing on the use case, this may require a time-consuming and only semi-
                                                                                            automatic process that does not scale for massive data sets, especially if
    3D point clouds allow for a discrete representation of real-world ob-                   precision, density and data quality of the derived 3D models need to be
jects and environments. They can be time-eﬃciently and cost-eﬃciently                       maximized. Moreover, improved scanning hardware and novel carrier
generated by a large number of acquisition techniques using active or                       systems, which get cheaper and easier-to-use, result in more dense 3D
passive sensing technology such as LiDAR, radar, or aerial and digi-                        point clouds. Thus, there is a strong demand to store, manage, process
tal cameras [13,29]. Integrated into a variety of carrier platforms such                    and explore massive, arbitrarily dense 3D point clouds in order to take
as airplanes, helicopters, UAVs, cars, trains, and robots, the sensing                      advantage of their full potential and to provide an unﬁltered, detailed
technology can capture data at diﬀerent scales, ranging from small as-                      representation of captured sites.
sets over buildings and infrastructure networks up to entire cities and                         In this paper, we present a web-based visualization system for mas-
countries [23,24,35]. The resulting data sets are essential for a grow-                     sive 3D point clouds (Fig. 1) based on spatial data structures and level-
ing number of applications in domains such as land surveying, urban                         of-detail representations that provide eﬃcient access to arbitrary subsets
planning, landscape architecture, environmental monitoring, disaster                        of the 3D point cloud stored on a central server component. By combin-
management, construction as well as spatial analysis and simulation                         ing out-of-core rendering concepts with web-based rendering concepts
[13,28,30].                                                                                 massive data sets can be simultaneously distributed to and interactively
    By their very nature, 3D point clouds are unstructured and do not                       visualized on an arbitrary number of client devices with diﬀerent com-
contain or imply any order or connectivity between individual points. As                    putation capabilities. To facilitate a collaborative inspection and to high-
a consequence, traditional analysis algorithms for geodata often strug-                     light task-relevant aspects of the data, diﬀerent point-based rendering
gle with 3D point clouds as they commonly rely on explicitly deﬁned                         and interaction techniques are implemented that can be combined and
connectivity information. Visualization algorithms often apply a uni-                       conﬁgured by the user. In addition, the system can take advantage of
form pixel size and render style to each point and, therefore, are prone                    per-point attributes generated by additional point-cloud analysis ser-
to visual artifacts such as holes or visual clutter which severely limits                   vices. We evaluate our system with real-world data sets containing up
perception, interaction, and navigation [37]. As a remedy, GIS applica-                     to 120 billion points. Results show that the system is capable to provide
tions frequently use 3D point clouds only as input data to derive mesh                      a powerful component in production workﬂows to manage, distribute
based 3D models (e.g., 3D city models, terrain models) [2]. Depend-                         and share 3D point clouds.



  ∗
      Corresponding author.
      E-mail addresses: soeren.discher@hpi.de (S. Discher), rico.richter@hpi.de (R. Richter), juergen.doellner@hpi.de (J. Döllner).

https://doi.org/10.1016/j.gmod.2019.101036
Received 2 November 2018; Received in revised form 2 May 2019; Accepted 8 June 2019
Available online 13 June 2019
1524-0703/© 2019 Elsevier Inc. All rights reserved.
S. Discher, R. Richter and J. Döllner                                                                                    Graphical Models 104 (2019) 101036




Fig. 1. Example of a massive 3D point cloud rendered with our web-based system. Context-providing geodata such as 2D maps and 3D terrain models can be
integrated into the visualization.


2. Related work                                                               for arbitrary large data sets, which is adapted by Martinez-Rubi et al.
                                                                              [25] to interactively present a massive data set of the Netherlands.
    3D point clouds represent a universal data category for a large num-      An alternative thick client renderer for 3D point clouds named Plasio
ber of geospatial applications [13,41]; many approaches exist to en-          was introduced by Butler et al. [6]: Using open-source libraries such
hance information implicitly contained in 3D point clouds by deriv-           as Entwine and Greyhound massive data sets can be streamed interac-
ing information about surface categories for each point, typically based      tively. GVLiDAR [11] and ViLMA [10] constitute thick client rendering
on local topological analysis [7] or by deep learning concepts [5,21].        approaches that focus on geospatial analysis and measurement tools.
Richter et al. [38] show how to eﬃciently identify changes in multi-          While all four frameworks provide eﬀective interaction and inspection
temporal data sets, which contain data acquired at diﬀerent points in         techniques speciﬁcally for 3D point clouds, they oﬀer only minimal sup-
time. Awrangjeb et al. [1] combine surface categories and change detec-       port to integrate additional, context-providing geodata (e.g., shapes, 2D
tion results to ﬁlter detected changes based on semantics. Our approach       maps). The Cesium 1 framework on the other hand aims to provide a
provides eﬃcient means to integrate such analyses as separate web pro-        generalized thick client rendering solution for arbitrary types of geodata
cessing services [27]. Furthermore, analysis results can be shared, ex-       (e.g., 3D point clouds, 3D meshes, 2D maps). Our approach is in parts
plored and inspected.                                                         based on that framework, expanding it by several semantics-dependent
    A general overview of point-based rendering techniques is pro-            rendering techniques and a set of interaction techniques for the collabo-
vided by Gross and Pﬁster [18]. High-quality rendering techniques             rative inspection of 3D point clouds (e.g., to share, query, and annotate).
[34,44] focus on minimizing artifacts such as visual clutter or visible           In addition, our approach also provides a thin client renderer, al-
holes between neighboring points by applying appropriate size, orien-         lowing to optionally reduce the performance impact on client-side by
tation, textures and color schemes to each rendered primitive. Often,         delegating the rendering to the server side. Compared to the aforemen-
such techniques apply surface splatting [3], rendering not the points         tioned frameworks, we can thus adapt to a broader range of computing
themselves but rather a set of arbitrary-shaped surface patches that          and graphics capabilities on client side. Similar approaches have been
approximate the underlying surface of a 3D point cloud. While surface         successfully implemented in the past [8,12,19] but typically focus on
splatting typically requires some preprocessing (e.g., to consolidate re-     mesh-based geometry rather than 3D point clouds. To generate stereo-
dundant surface patches or to apply texturing [16]), it can signiﬁcantly      scopic panoramas we implemented the theoretical concepts described
increase the realism of a point cloud depiction. Non-photorealistic ren-      by [31] by means of modern 3D computer graphics.
dering techniques [46,50], on the other hand, deal with the fuzziness of          Systems for the eﬃcient management of massive 3D point clouds
a 3D point cloud and highlight edges and structures, commonly without         have been recently presented and evaluated by [9], [48], and [33].
requiring any preprocessing or additional attributes apart from a point’s     However, those contributions focus on the eﬃcient storage, retrieval
spatial position [4,32]. In our approach, we implement high-quality as        and processing of the stored data sets. Less emphasis is put on the col-
well as non-photorealisitic rendering techniques. They can be switched        laborative exploration, inspection and manipulation of the stored data
and conﬁgured at runtime.                                                     sets.
    Out-of-core rendering concepts for massive 3D point clouds were ini-
tially introduced by Rusinkiewicz and Levoy [40]. State-of-the-art tech-      3. Requirements
niques typically use spatial data structures such as layered, regular grids
[10], quadtrees [15], octrees [14,49], or KD-trees [17] to subdivide the         We have identiﬁed the following requirements that need to be ad-
data into smaller subsets that can be selected dynamically, e.g., based       dressed by a system for the web-based visualization and collaborative
on the current view frustum and memory budget.                                exploration of massive 3D point clouds:
    Recent approaches combine out-of-core and web-based rendering
concepts to enable a ubiquitous visualization of 3D point clouds [39].
                                                                               1
With Potree, Schütz and Wimmer [45] propose a thick client approach                https://cesiumjs.org.
S. Discher, R. Richter and J. Döllner                                                                                              Graphical Models 104 (2019) 101036




                        Fig. 2. System architecture showing data ﬂow between integration, processing, visualization, and interaction components.


    R1 Use of 3D point clouds as a fundamental geometry type instead                  singular component, the data itself may be stored in a distributed infras-
       of generalized mesh-based representations to enable a direct and               tructure, e.g., to maximize data throughput and network transfer rates
       unﬁltered provision of the data.                                               or to account for data speciﬁc requirements regarding server location
    R2 No limitations regarding used acquisition methods as well as den-              and data security (R4).
       sity, resolution, and scale of the data (e.g., hundreds of billions
       of points, complete countries).                                                4.2. Workspace manager
    R3 Support for varying hardware platforms and computation capa-
       bilities, ranging from high-end desktop computers to low-end mo-                    The workspace manager handles information speciﬁc to a workspace,
       bile devices.                                                                  i.e., each user’s private view of a speciﬁc data subset containing cus-
    R4 Distributed data storage to enable load balancing and to adjust                tom selections, measurements, annotations, view positions, and angles.
       for data speciﬁc requirements (e.g., certain 3D point clouds might             Per default, each user operates in its own private workspace rather than
       have to be stored on a speciﬁc server).                                        sharing one globally with everyone else to avoid conﬂicting modiﬁca-
    R5 Capabilities to prepare and clean up 3D point clouds for the vi-               tions (R11). However, a given workspace may be shared via links (R12).
       sualization (e.g., noise and outlier removal).                                 Each user may also own multiple workspaces.
    R6 Capabilities to conduct task and data speciﬁc analyses on 3D
       point clouds (e.g., surface category extraction) to provide adap-              4.3. Geodata manager
       tive and task speciﬁc content.
    R7 Visualization of analysis results (e.g., surface categories) to en-               By application-speciﬁc geodata, we refer to additional geodata that
       able task speciﬁc highlighting and ﬁltering.                                   should be used and rendered in combination with a 3D point cloud
    R8 Capabilities to compare and show diﬀerences between 3D point                   to provide application-speciﬁc information layers (R9). Examples are
       clouds from diﬀerent points in time of the same site (i.e., change             digital terrain models, aerial images, BIM models, or 3D city models.
       detection).                                                                    Similar to 3D point clouds, these data types also require supplemental
    R9 Integration of supplementary, context-providing geodata such as                level-of-detail representations to allow for an interactive visualization.
       2D maps.                                                                       Application-speciﬁc geodata can be stored and provided by independent
    R10 Provision of interaction techniques to inspect (e.g., measuring               geospatial databases or geodata services, access to which is handled by
       of distances, areas, volumes) and annotate 3D point clouds.                    the geodata manager.
    R11 Basic user management to customize data access.
    R12 Capabilities to share speciﬁc rendering conﬁgurations, annota-                4.4. Processing engine
       tions and measurements with others (e.g., via link).
                                                                                          The processing engine conducts task and data speciﬁc operations on
4. Concepts                                                                           a given data subset. These operations range from (a) essential prepro-
                                                                                      cessing steps (e.g., converting input data sets into a homogeneous geo-
    We have addressed the aforementioned requirements in the design                   reference system or generating level-of-detail representations), over (b)
and implementation of our web-based system that seamlessly com-                       simple point cloud ﬁltering (e.g., noise and outlier removal (R5)) to (c)
bines functionality to integrate, process, and collaboratively explore                more complex analyses (e.g., surface category extraction and change
massive, heterogeneous 3D point clouds as well as supplementary,                      detection (R6)) deriving additional per-point attributes. The operations
context-providing geodata. The proposed system (Fig. 2) consists of the               can be accessed via web processing services implemented as separate
following major components:                                                           web services that are individually combined and scheduled by the pro-
                                                                                      cessing engine. Thus, existing web processing services for 3D point
4.1. Point cloud manager                                                              clouds can be easily integrated into the system. The results of each op-
                                                                                      eration are automatically stored by the point cloud manager and can be
    In our approach, 3D point clouds are organized in a single, homo-                 seamlessly integrated by the rendering engine (Section 4.5) into depic-
geneous spatial data model. Access to that model is handled by the                    tions of the corresponding site (R7).
point cloud manager storing spatial information and additionally pro-
vided or computed per-point attributes (e.g., temporal information or                 4.5. Rendering engine
surface categories) (R1). Level-of-detail representations [14,17] are re-
quired to eﬃciently access arbitrary data subsets of any size based on                    Providing the core functionality of our system, the rendering engine
spatial, temporal or any other attributes. These representations as well              is responsible for interactively visualizing three types of data: (a) 3D
as additional per-point attributes can be generated by the processing en-             point clouds featuring a varying number of per-point attributes, (b) task-
gine (Section 4.4) (R2). While the point cloud manager logically acts as a            speciﬁc geodata providing context (e.g., maps (R9)), and (c) workspace
S. Discher, R. Richter and J. Döllner                                                                                       Graphical Models 104 (2019) 101036


elements resulting from user interactions (e.g., annotations or selection       tree structures and minimal data access times. Context providing geo-
and measurement indicators (R10)). For each of those data types the             data and workspace elements are organized in similar fashion.
corresponding manager is queried, retrieving only data subsets that are
relevant for the current view and task. To highlight certain aspects of         5.1. Pipeline architecture
the data (e.g., temporal changes or surface categories in an area), diﬀer-
ent point-based rendering techniques and post processing eﬀects can be              The applied pipeline architecture is based on the concept of so-called
combined (R8). Changes to the currently applied render conﬁguration             processing pipelines, each of which described by a pipeline plan deﬁning
can be made dynamically via the interaction handler) (Fig. 3). In general,      a speciﬁc combination of basic input, processing and output operations.
retrieved data subsets will be transferred to and rendered on client side,      To be more precise, a pipeline plan may contain the following elements
which minimizes the workload on the server (i.e., thick clients). As an         (also referred to as pipeline nodes):
alternative, server-side rendering can be applied to reduce the perfor-
mance impact for clients (i.e., thin clients). Thus, the system scales for          •   Importers, i.e., pipeline nodes that import 3D point clouds, either
a broad range of devices, ranging from high-end workstations to mobile                  ﬁle based or directly from the point cloud manager. For each
devices (R3).                                                                           data source and ﬁle format (e.g., LAS, E57) a separate importer is
                                                                                        provided. Each importer prepares data packages. If the input data
4.6. Interaction handler                                                                exceeds the maximum data package size, the importer prepares
                                                                                        subsets by splitting the data.
                                                                                    •   Exporters, i.e., pipeline nodes that export pipeline results. This
   The interaction handler is responsible for handling user interactions
as well as for updating the rendered data and workspace elements ac-                    can refer to Level-of-Detail representations, additional point at-
cordingly (R10, Fig. 4). Users may                                                      tributes or artiﬁcially generated 3D point clouds, but also to addi-
                                                                                        tional geodata (e.g., shape ﬁles, CityGML, GeoTIFFs). All results
      •   deﬁne or load workspaces,                                                     are then stored by the corresponding manager, allowing to seam-
      •   select which data subsets to render,                                          lessly integrate them into the visualization.
      •   conﬁgure the presentation of the data (with regards to applied            •   Tasks, i.e., pipeline nodes that implement a speciﬁc processing
          rendering techniques),                                                        or analysis algorithm. Some algorithms operate on multiple data
      •   select, query and highlight individual points or groups of points,            sets simultaneously (e.g., to compare or to merge them). Sim-
      •   measure distances and areas between selected points,                          ilarly, algorithms may split incoming data sets or yield multi-
      •   annotate selected points or areas,                                            ple results (e.g., additional per-point attributes and correspond-
      •   modify annotations,                                                           ing shapes). Hence, multiple incoming and outgoing connections
      •   saving and loading view positions and angles.                                 may be deﬁned per task.
                                                                                    •   Connections, i.e., links between two pipeline nodes for the trans-
5. Processing engine implementation                                                     fer of data packages. They deﬁne the order of execution. A given
                                                                                        connection transfers only packages of a speciﬁc type (e. g., 3D
    Data and use case speciﬁc operations on 3D point clouds typically                   point clouds or shapes). Depending on the pipeline nodes being
combine several atomic processing steps (e.g., determining a point’s                    connected, various constraints may be deﬁned, such as deﬁned
closest neighbor or aggregating attribute values within the local neigh-                per-point attributes that are required.
borhood of a point) that can be executed independently on a small area              •   Data Packages, i.e., data subsets that are transferred between
around each point [5,7,36,38]. Therefore, the processing performance                    pipeline nodes via connections. Similar to connections, a given
can be signiﬁcantly increased by applying parallel computing concepts,                  data package may only contain a speciﬁc type of geodata. Also,
either based on a CPU or a GPU. Diﬀerent processing and analysis oper-                  the size of the corresponding data subset may not exceed a spe-
ations can be eﬃciently chained together by interleaving them. Instead                  ciﬁc maximum deﬁned by the resource manager.
of executing each operation one at a time for the complete data set,
processed subsets are immediately subjected to subsequent operations.               Pipeline plans are executed by the pipeline engine. Several pipeline
Since 3D point clouds commonly exceed available capacities of main              plans can be executed in parallel; every single one can also be dynami-
or GPU memory, these parallel computing concepts need to combined               cally started, paused and stopped. At runtime, each active pipeline node
with out-of-core approaches that subdivide the overall data set into suf-       gets assigned its own set of resources by the resource manager, responsi-
ﬁciently small subsets.                                                         ble for monitoring and distributing memory and processing usage within
    The processing engine uses a modular pipeline architecture (Fig. 5)         a system. Processed data packages are immediately transferred to sub-
that combines parallel computing and out-of-core concepts: Basic pro-           sequent pipeline nodes. Pipeline nodes manage a queue of incoming
cessing and analysis operations can be freely combined and applied to           data packages for each incoming connection, whose size is restricted to
arbitrary large data sets, making optimal use of available hardware re-         a maximum number of data packages that can be deﬁned at runtime.
sources by parallelizing, interleaving, and distributing operations along-      If a queue reaches its maximum capacity, no additional data packages
side corresponding data subsets between computing resources (e.g., dif-         are accepted and preceding nodes are not executed. To improve their
ferent servers in a distributed environment). The processing and analy-         runtime performance, the most time-consuming pipeline nodes are exe-
sis operations involved are described via processing pipelines that can         cuted in parallel by adaptively assigning additional resources (e.g., CPU
be reconﬁgured and replaced at runtime. We allow for an eﬃcient re-             or GPU cores).
trieval of arbitrary subsets by means of a multi-layer hierarchical subdi-
vision: For each 3D point cloud, a separate spatial data structure is gen-      5.2. Memory and resource management
erated that best compliments the spatial distribution of the correspond-
ing points (e.g., quadtrees for airborne data sets, octrees or kd-trees for         The resources of a system may be distributed across several servers
terrestrial data sets). In turn, those spatial data structures are integrated   in a network, each featuring diﬀerent memory capacities (i.e., size of
into an overarching quadtree, allowing to eﬃciently answer queries              secondary storage, main memory, and GPU memory) and computing
stretching across multiple data sets. Compared to uniform, single-layer         capabilities (e.g., number and clock speed of CPU and GPU cores, mem-
spatial data structures (e.g., as they are used by Schütz and Wimmer            ory transfer rates). Servers and their resources are added to a global
[45]), this avoids a time consuming rebalancing when new 3D point               resource pool that is monitored by the resource manager of the system.
clouds are added to the system while simultaneously ensuring balanced           Whenever a pipeline node needs to be executed, the resource manager
S. Discher, R. Richter and J. Döllner                                                                                             Graphical Models 104 (2019) 101036




                                        Fig. 3. Diﬀerent point-based rendering styles can be selected and conﬁgured at runtime.




                                             Fig. 4. Overview of implemented interaction techniques for 3D point clouds.
S. Discher, R. Richter and J. Döllner                                                                                       Graphical Models 104 (2019) 101036


                                                                               cloud that are manageable by available CPU and GPU capabilities can
                                                                               be queried dynamically from the point cloud manager by specifying the
                                                                               current view frustum, main and GPU memory budgets as well as task
                                                                               speciﬁc qualiﬁers (e.g., value ranges for selected per-point attributes)
                                                                               to ﬁlter the corresponding data sets. In particular, we use the resulting
                                                                               screen-space error as a metric to evaluate potentially ﬁtting subsets, op-
                                                                               timizing towards a maximum allowed screen-space error: The higher the
                                                                               allowed screen-space error, the less points need to be queried and ren-
                                                                               dered, albeit at the cost of further reducing precision and density of the
                                                                               point cloud depiction. To accommodate for changing network latencies,
                                                                               the maximum can be adjusted at runtime. Since hardware speciﬁcations
                                                                               of clients can not be queried from a web browser, main and GPU mem-
                                                                               ory budgets need to be speciﬁed manually. To assist users in specifying
      Fig. 5. Overview of the pipeline architecture and pipeline elements.     a reasonable budget, we optionally provide a set of predeﬁned budget
                                                                               conﬁgurations that have been tested for a variety of common hardware
                                                                               setups. To enable an eﬃcient subset retrieval, the data is hierarchically
                                                                               subdivided in a pre-processing step (Section 5) before being made ac-
                                                                               cessible by the point cloud manager. Context providing geodata and
                                                                               workspace elements are handled similarly and can be queried simulta-
                                                                               neously from their respective manager when required.

                                                                               6.2. Rendering

                                                                                   After being queried from the respective managers, 3D point clouds,
                                                                               context providing geodata and interactive workspace elements are ren-
                                                                               dered into separate g-buﬀers [42], i.e., specialized frame buﬀer objects
                                                                               (FBO) combining multiple 2D textures for, e.g., color, depth, normal, or
                                                                               id values. The use of id values is important to separate point clouds from
                                                                               context data. Each rendered point has a unique identiﬁer, stored in an
                                                                               id texture, to allow for an eﬃcient point selection, e.g., to implement
Fig. 6. Overview of the rendering pipeline. Each data type is managed and      interaction features (Section 6.3). In addition, diﬀerent rendering styles
rendered separately.                                                           can be conﬁgured and applied at runtime. As an example, size and color
                                                                               of each point can be modiﬁed based on selected per-point attributes
assigns resources based on available memory and processing capabili-           (e.g., surface categories, topological metrics) to enable task speciﬁc vi-
ties. After the execution is ﬁnished, all assigned resources are released      sual ﬁltering and highlighting (Fig. 4). Similarly, several options exist
to the resource pool and become available for other nodes (Fig. 5). Dis-       to dynamically adjust the appearance of mesh-based geometry, ranging
tributing resources requires the resource manager to make a trade-oﬀ           from transparency settings to changeable texture mappings.
between several, often contradicting optimization goals:
                                                                               6.3. Image compositing
      •   Exclusivity. Exclusive access to a resource (e.g., storage or GPU)
          signiﬁcantly improves the runtime performance of a pipeline
                                                                                   A ﬁnal image compositing stage is used to merge the separate g-
          node (e.g., by minimizing cache misses and seek times).
                                                                               buﬀers, i.e., to combine several independently generated views of 3D
      •   Transfer Costs. Frequently transferring data packages via con-
                                                                               point sub-clouds into a ﬁnal image. For example, image-based post pro-
          nections may notably reduce the performance if subsequent
                                                                               cessing eﬀects emphasizing edges and depth diﬀerences (e.g., Screen
          pipeline nodes operate on diﬀerent servers. This can be avoided
                                                                               Space Ambient Occlusion [26] or Eye Dome Lighting [4]) can be applied
          by executing them on the same server.
                                                                               at that stage to improve the visual identiﬁcation of structures within 3D
      •   Parallelization. Executing pipeline nodes in parallel or inter-
                                                                               point cloud depictions (Fig. 7). The id textures stored by the g-buﬀers
          leaved is an essential mechanism to improve the overall perfor-
                                                                               provide eﬃcient means to identify which point was rendered at a spe-
          mance of the system. Thus, available resources and servers should
                                                                               ciﬁc pixel. Thus, individual points can be selected in real-time, which
          be shared among as many pipeline nodes as possible.
    The runtime of nodes may vary signiﬁcantly depending on the op-
eration. An adaptive resource scheduling allows to handle bottlenecks
in processing pipeline. The execution time is tracked for each node and
the number of assigned resources is adjusted dynamically.

6. Rendering engine implementation

   To seamlessly combine 3D point clouds, context providing geodata
and interactive workspace elements into a homogeneous visualization,
a multi-pass rendering pipeline is used that consists of three distinct
stages (Fig. 6):

6.1. Level-of-detail and data subset selection

    While 3D point clouds may easily contain billions of points, only a        Fig. 7. Post-processing eﬀects such as Eye Dome Lighting facilitate visual ﬁl-
fraction of that data is required to render a frame. Subsets of the 3D point   tering and highlighting.
S. Discher, R. Richter and J. Döllner                                                                                      Graphical Models 104 (2019) 101036


                                                                              and Cesium 4 for thick client applications. For thin client applications,
                                                                              server-side rendering is based on OpenGL, glbinding 5 and GLFW 6 . On
                                                                              client-side, Three.js 7 , WebGL, and WebVR Polyﬁll 8 are combined to dis-
                                                                              play 2D as well as stereoscopic panoramas. For data compression we
                                                                              use gzip 9 and lodePNG 10 , respectively. Evaluated 3D point clouds are
                                                                              represented by separate kd-trees, that in turn are integrated into an over-
                                                                              arching quadtree. We opted to use kd-trees to optimize the balancedness
                                                                              of the tree structures, speeding up the subset retrieval, albeit at the cost
                                                                              of a prolonged preprocessing. Those spatial data structures and corre-
                                                                              sponding data subsets are serialized into ﬁles acting as a point cloud
Fig. 8. Comparison of web-based rendering concepts: Thin clients vs thick     database. Similar, ﬁle-based approaches are applied to store and access
clients.                                                                      context-providing geodata and workspace elements.

                                                                              7.1. Performance tests
is an essential requirement to support annotating points or measuring
distances and areas.
                                                                                  A desktop computer featuring an AMD Ryzen 7 1700 CPU, 32 GB
                                                                              main memory and an NVIDIA GeForce GTX 1070 with 8 GB device mem-
6.4. Web-based rendering
                                                                              ory was used as a server for the initial performance tests. The test data
                                                                              sets included a terrestrial, indoor scan of an individual site (1.33 bil-
    To accommodate for client devices with varying computation capa-
                                                                              lion points), a mobile mapping scan (2.57 billion points) and a massive,
bilities, diﬀerent web-based rendering concepts are combined with the
                                                                              multi-temporal data set of an urban region (120 billion points) captured
presented rendering pipeline (Fig. 8). We provide a thick client applica-
                                                                              by airborne devices. For all data sets essential preprocessing steps (i.e.,
tion that uses a central server infrastructure to organize, process, select
                                                                              spatial data structure generation) and ﬁltering (i.e., noise and outlier
and distribute the data, but delegates the actual rendering of selected
                                                                              removal) were performed by the processing engine. In addition, surface
data subsets to the clients. This approach signiﬁcantly reduces workload
                                                                              categories (i.e., ground, building, vegetation) and changes in compari-
on server side, allowing to serve massive numbers of clients simultane-
                                                                              son to earlier scans were extracted for the airborne data set, allowing
ously. Transferred data subsets are cached on client side up to a device
                                                                              to evaluate the system’s ability to dynamically combine diﬀerent ren-
speciﬁc limit, thus, minimizing the frequency of data requests for sub-
                                                                              dering styles. The average data throughput for the applied processing
sequent frames. In fact, additional data subsets are only required if the
                                                                              operations is listed in Table 2.
view frustum changes signiﬁcantly, whereas inspecting the transferred
                                                                                  The rendering engine was evaluated based on four diﬀerent scenes
data or changing the applied rendering style triggers no such requests.
                                                                              (Fig. 9) with client applications running on a number of diﬀerent devices
Alternatively, in the sense of a thin client approach, the data can be ren-
                                                                              and web browsers (Table 1). As opposed to aforementioned state-of-the-
dered directly on the server, supplying only the resulting images. While
                                                                              art rendering frameworks for 3D point clouds such as Potree, Plasio,
this comes with the drawback of increased workload on server side as
                                                                              GVLiDAR or ViLMA, our rendering engine provides both, a thick client
any user interactions trigger a new data request, hardware requirements
                                                                              and a thin client renderer. Thus, the rendering process can be shifted
for clients are notably reduced. A common optimization for such thin
                                                                              dynamically between client and server side depending on network con-
client applications is to render and transfer cube-maps or virtual panora-
                                                                              ditions and a client’s computing and graphics capabilities, allowing us
mas instead of individual images [12,20]. This provides clients with
                                                                              to support a broader range of hardware platforms.
eﬃcient means to locally reconstruct the 3D scene for a speciﬁc view
                                                                                  Our Cesium-based thick client implementation allows to render sev-
position. Thus, the data only has to be rendered anew whenever the
                                                                              eral millions of points simultaneously at interactive frame rates (i.e.,
view center or the rendering style are modiﬁed, which signiﬁcantly re-
                                                                              >30 fps) on standard desktop computers and notebooks (Table 4). On
duces the frequency of data requests for subsequent frames. Our system
                                                                              mobile devices, frame rates are signiﬁcantly lower due to the more lim-
provides a thin client application that expands that concept, distribut-
                                                                              ited computing capabilities. However, arbitrary large data sets can be
ing not only traditional 2D panoramas but also stereoscopic panoramas.
                                                                              visualized on all evaluated devices by assigning device-speciﬁc memory
Thus, emerging virtual reality technologies allowing for an immersive
                                                                              budgets, thus, limiting the density of the point cloud depiction. Over-
exploration of 3D point clouds even on mobile devices can be easily in-
                                                                              all, rendering performance and visual quality are similar to what can be
tegrated. We generate those stereoscopic panoramas by rendering sev-
                                                                              achieved by aforementioned state-of-the-art approaches such as Potree,
eral equally-sized image strips along a viewing circle that are stitched
                                                                              Plasio, GVLiDAR or ViLMA. However, our thick client implementation
together in a post-processing step [31]. The visual quality of the panora-
                                                                              allows to seamlessly integrate additional geodata as well as analysis re-
mas depends on the requested resolution as well as the number of image
                                                                              sults which greatly facilitates an in-depth inspection.
strips; both settings can be speciﬁed upon requesting a new panorama.
                                                                                  On the other hand, our thin client implementation provides a uni-
To further reduce overall network load, both applications dynamically
                                                                              form rendering quality on all client devices since the panoramas are
compress and decompress the transferred data, using common standards
                                                                              generated on server side, minimizing workload on client side. On all
such as gzip (for thick clients) and png (for thin clients), respectively.
                                                                              evaluated devices we measured frame rates close to the correspond-
We decided against using any lossy compression standards (e.g., jpeg
                                                                              ing display’s refresh rate (e.g., 60 fps on the Galaxy S7), making our
compression) to maximize visual quality.
                                                                              approach applicable to state-of-the-art VR devices such as GearVR or
                                                                              Oculus Rift. The performance of the panorama generation is primarily
7. Evaluation

   We have implemented the presented concepts on the basis of several          4
                                                                                   https://cesiumjs.org.
C++ and Javascript libraries. The processing engine uses CUDA 2 and            5
                                                                                   https://github.com/cginternals/glbinding.
                                                                               6
the Point Cloud Library 3 . Regarding the rendering engine, we use WebGL           http://www.glfw.org.
                                                                               7
                                                                                   https://threejs.org.
                                                                               8   https://github.com/immersive- web/webvr- polyﬁll.
  2                                                                            9
      https://developer.nvidia.com/cuda-zone.                                      http://www.gzip.org.
  3                                                                           10
      http://pointclouds.org.                                                      http://lodev.org/lodepng/.
S. Discher, R. Richter and J. Döllner                                                                                                   Graphical Models 104 (2019) 101036


                       Table 1
                       Devices used to evaluate the rendering engine. All web browsers were updated to the latest version as of 04/20/2018.

                         Client Device      CPU                    Main Memory     GPU                     Evaluated Web Browsers

                         Lenovo M710t       Intel Core i7-6700     32GB            GeForce GTX 1050Ti      Chrome, Firefox, Opera, Edge
                         Macbook Pro 13′′   Intel Core i5-4278U    16GB            Intel Iris 5100         Safari, Chrome, Firefox
                         iPhone SE          Apple A9 @ 1.84 GHz    2GB             PowerVR GT7600          Safari Mobile, Chrome Mobile
                         Galaxy s7          Samsung Exynos 8890    4GB             ARM Mali-T880 MP12      Samsung Internet Browser, Chrome Mobile



                                                                                                   Table 2
                                                                                                   Average data throughput of the processing engine.

                                                                                                     Processing Operation           Average Data Throughput

                                                                                                     Noise & Outlier Filtering      1.26B pts/h
                                                                                                     Surface Category Extraction    0.10B pts/h
                                                                                                     Change Detection               1.42B pts/h
                                                                                                     Kd-Tree Generation             4.85B pts/h




                                                                                         quests, even if gzip compression is applied (Table 3). However, they
                                                                                         do not require all those data subsets at once, allowing to update the
                                                                                         scene progressively. Furthermore, while exploring a 3D point cloud, the
                                                                                         view will usually change only gradually across subsequent frames, al-
                                                                                         lowing for thick clients to reuse many of the previously transferred data
                                                                                         subsets, thus, resulting in smaller and faster scene updates over pro-
                                                                                         longed explorations. Changes to the rendering style as well interaction
                                                                                         techniques such as picking, selecting or measuring don’t trigger any ad-
              Fig. 9. Scenes used during the intial performance tests.                   ditional data requests at all and can be applied even under unstable
                                                                                         network conditions. For thin client applications on the other hand, no
                                                                                         parts of the previously transferred data can be reused if the currently
                                                                                         used panorama becomes invalid: Navigating -apart from merely look-
inﬂuenced by the requested resolution and to a lesser degree on the                      ing around from a ﬁxed position- as well as rendering style adjustments
number of image strips used (Table 5).                                                   require the server to generate and transfer a new panorama as a replace-
    For all evaluated scenes, thick client applications require to trans-                ment. Similar to thick clients however, picking, selecting or measuring
fer signiﬁcantly more data for an individual scene than thin clients as                  can be conducted on the already transferred data and does not trigger
long as no reusable data subsets have been cached from previous re-                      any new data requests.




                           Fig. 10. Web frontend used during the ﬁrst case study allowing users to upload, prepare and explore 3D point clouds.
S. Discher, R. Richter and J. Döllner                                                                                                                      Graphical Models 104 (2019) 101036


                         Table 3
                         Average data throughput of the rendering engine based on the scenes deﬁned in Fig. 9. For thin clients, a stereoscopic
                         panorama was created per request. While the same, device-dependent resolution was requested for each scene, diﬀerent
                         entropies aﬀected the compressed image size.

                                                        Thick Client                              Thin Client
                           Scene
                                                        Transferred Data       Transfer Time      Transferred Data     Panorama Generation Time        Transfer Time

                           Terrestrial                  156.2 MB               16.18s             4.68 MB              5.27s                           1.36s
                           Mobile Mapping               140.7 MB               14.15s             4.16 MB              5.05s                           1.27s
                           Airborne (zoomed out)        16.1 MB                3.43s              4.15 MB              4.96s                           1.22s
                           Airborne (zoomed in)         82.4 MB                8.09s              4.54 MB              5.13s                           1.32s


                                    Table 4
                                    Average performance rate of the thick client for diﬀerent point budgets based on the airborne data set
                                    (Fig. 9d).

                                        Number of              Transferred Data    Transferred Data       Lenovo        Macbook    iPhone         Galaxy
                                        Points                 (uncompressed)      (compressed)           M710t         Pro13′′    SE             s7

                                        2M pts                 29.5 MB             26.2 MB                122.63fps     53.85fps   41.83fps       39.96fps
                                        4M pts                 57.4 MB             50.9 MB                84.48fps      45.63fps   36.44fps       35.29fps
                                        6M pts                 85.6 MB             76.1 MB                63.23fps      39.08fps   26.36fps       24.83fps
                                        8M pts                 113.6 MB            100.7 MB               56.87fps      35.83fps   19.65fps       18.43fps


                                                 Table 5
                                                 Panorama generation time for diﬀerent conﬁgurations based on the terrestrial data set
                                                 (Fig. 9a).

                                                                     Transferred        Panorama Generation Time
                                                  Resolution         Data
                                                                                        90 image strips     120 image strips   160 image strips

                                                  2360x1600 px       2.33 MB            1.88s               2.26s              2.29s
                                                  2360x3200 px       4.68 MB            4.20s               4.68s              5.27s
                                                  2360x6400 px       9.35 MB            6.17s               7.14s              7.88s




7.2. Case studies

    The initial performance evaluation was followed up by two case
studies to demonstrate the scalability of our approach with regards
to user base, data size as well as available computing and graphics
capacities.
    The ﬁrst case study focused on the collaborative interaction with
3D point clouds in the context of a large-scale infrastructure project in-
volving up to 10 concurrent users representing diﬀerent stakeholders
spread across Germany. The infrastructure project comprised several
individual sites that were captured by air or – in the case of some                                  Fig. 11. Processing pipelines as they have been used for the presented case
especially relevant building complexes – via terrestrial scanning. In                                studies.
total, the scans amounted to 5.31 TB of raw data (E57 or las format)
distributed across 144 individual data sets, each of which containing
between 18 million to 4.1 billion points at an average point density of
6.1 points/m2 (airborne scans) and 1.2 million points/m2 (terrestrial
scans), respectively. Via a web frontend (Fig. 10) users were able to
(1) upload data sets asynchronously, (2) georeference them individually
and (3) restrict data access to speciﬁc users. Simultaneously – given cor-
responding data access rights – users could collaboratively inspect and
annotate 3D point clouds that have already been added to the system
as described in Section 4. Rendering performance on client devices was
consistent with the results presented in Section 7.1. A dedicated server
featuring an Intel Core i7-8700 CPU, 64 GB main memory and 12 TB
secondary storage was used to host uploaded data sets and conduct nec-
essary pre-processing operations. The applied processing pipeline was
rather simplistic, combining just three pipeline nodes (Fig. 11): An im-
porter and an exporter, connected via a kd-tree generator task. To speed
up performance, each kd-tree generator uses a main memory cache. In                                  Fig. 12. Cache size was limited to 16 GB per kd-tree generator for the case
the context of this case study, the maximum cache size was set to 16                                 study. Hence, the number of kd-trees that could be generated in parallel (bars)
GB, thus, the number of kd-trees that could be generated in parallel                                 varied depending on the overall size of the corresponding raw data (area). (For
was limited to four in the worst case (Fig. 12). However, even for the                               interpretation of the references to colour in this ﬁgure legend, the reader is
largest uploaded data sets pre-processing times stayed below 60 min.                                 referred to the web version of this article.)
S. Discher, R. Richter and J. Döllner                                                                                         Graphical Models 104 (2019) 101036




Fig. 13. Computation time in minutes of the change detection for diﬀerent num-   Fig. 15. Computation time in minutes of the change detection for diﬀerent num-
bers of CPU cores used (for one GPU).                                            bers of GPUs used (for 28 CPU cores).


                                                                                 for data analysis: Per-point attributes as well as the pipeline nodes used
                                                                                 by the processing engine share common interfaces which facilitates the
                                                                                 implementation of additional importers, exporters or tasks. The corre-
                                                                                 sponding pipeline plans are deﬁned via JSON ﬁles and can thus be easily
                                                                                 customized. Similiarly, the rendering engine allows to deﬁne and apply
                                                                                 custom GLSL shaders to adapt the visualization.

                                                                                 8. Conclusion and future work

                                                                                     Web-based visualization and exploration of massive 3D point clouds
                                                                                 from aerial, mobile, or terrestrial data acquisitions represent a key fea-
                                                                                 ture for today’s and future systems and applications dealing with digital
                                                                                 twins of our physical environment. In our web-based approach, we show
                                                                                 a system architecture that scalably visualizes massive 3D point clouds
                                                                                 to web-based client devices. To cope with extremely large number of
                                                                                 points, the implementation relies on spatial data structures and level-
                                                                                 of-detail representations, combined with diﬀerent out-of-core rendering
Fig. 14. Computation time in minutes of the surface category extraction for
diﬀerent numbers of CPU cores used (for one GPU).                                and web-based rendering concepts. Since the rendering process can be
                                                                                 shifted from client side to server side, the system can be easily adapted
                                                                                 to varying network conditions and to clients with a broad range of com-
Furthermore, they were added only gradually which further minimized              puting and graphics capabilities. Tests and case studies on data sets with
the delay noticeable by the users.                                               up to 120 billion points show the usability of the system and the feasibil-
    For the second case study, emphasis was put onto the processing en-          ity of the approach. As future work we plan additional case studies with
gine’s performance and scalability in more computation intense scenar-           regard to our system’s performance in distributed server environments.
ios. Hosted on an Oracle Server – featuring an Intel Xeon Gold 5120M             Various rendering techniques allow us to ﬁlter and highlight subsets of
CPU, 192 GB main memory, 8 TB secondary storage, and two NVIDIA                  the data based on any available per-point attributes (e.g., surface cate-
Tesla P100 with 16 GB device memory – we conducted a change detec-               gories or temporal information), which is required to build task-speciﬁc
tion as well as a surface category extraction for all uploaded data sets         or application-speciﬁc tools. Various interaction methods (e.g., for col-
using the processing pipeline depicted in Fig. 11. Users were then able          laborative measurements and annotations), built-in support to display
to interactively inspect the processing results by switching between dif-        context-providing, mesh-based geodata, and the possibility to conduct
ferent rendering styles as described in Section 4. Test data for that case       diﬀerent processing and analysis operations provide additional features.
study consisted of two diﬀerent airborne scans of a rural area of 270 km2        Our system could be further extended by integrating additional analyses
featuring 4 points/m2 (1.012 billion points in total) and 9 points/m2            (e.g., for asset detection, or surface segmentation) [22,47] as well as by
(2.474 billion points in total), respectively. The computation time of           specialized interaction techniques. For example, Scheiblauer and Wim-
both processing operations was notably reduced by increasing the num-            mer [43] and Wand et al. [49] propose spatial data structures that allow
ber of CPU threads used in parallel (Figs. 13 and 14) which underlines           for an interactive editing of 3D point clouds. In addition, sophisticated
the scalability of our approach. The performance of the change detec-            visualization techniques for multi-temporal 3D point clouds are becom-
tion could be improved further by increasing the number of GPUs used             ing more and more important to understand captured environments.
during the computation (Fig. 15), whereas that had only a neglectable
eﬀect on the – in that case – mostly CPU based surface category ex-              Acknowledgments
traction.
                                                                                     We thank Pawel Böning and Pascal Führlich for their contributions
7.3. Expandability                                                               to the thin client implementation as well as Heiko Thiel, Marcel Wendler
                                                                                 and Pawel Glöckner for their input on the thick client implementation.
   The proposed web-based system can be easily adapted for speciﬁc               Presented data sets have been provided by Illustrated Architecture, SHH
applications by adding custom visualization techniques or algorithms             sp. z o.o. and virtualcitySYSTEMS.
S. Discher, R. Richter and J. Döllner                                                                                                                   Graphical Models 104 (2019) 101036


References                                                                                         [24] T. Langner, D. Seifert, B. Fischer, D. Goehring, T. Ganjineh, R. Rojas, Traﬃc aware-
                                                                                                        ness driver assistance based on stereovision, eye-tracking, and head-up display, in:
 [1] M. Awrangjeb, C.S. Fraser, G. Lu, Building change detection from liDAR point cloud                 Proceedings of ICRA 2016, 2016, pp. 3167–3173.
     data based on connected component analysis, ISPRS Ann. Photogramm. Remote                     [25] O. Martinez-Rubi, S. Verhoeven, M.V. Meersbergen, M. Schûtz, P.V. Oosterom,
     Sens. Spat. Inform. Sci. 2 (2015) 393–400.                                                         R. Gonçalves, T. Tijssen, Taming the beast: Free and open-source massive point cloud
 [2] M. Berger, A. Tagliasacchi, L. Seversky, P. Alliez, J. Levine, A. Sharf, C. Silva, State of        web visualization, in: Proceedings of the Capturing Reality Forum 2015, 2015.
     the art in surface reconstruction from point clouds, in: EUROGRAPHICS Star Reports,           [26] M. Mittring, Finding next gen: cryengine 2, in: ACM SIGGRAPH 2007 courses. ACM,
     volume 1, 2014, pp. 161–185.                                                                       2007, pp. 97–121.
 [3] M. Botsch, A. Hornung, M. Zwicker, L. Kobbelt, High-quality surface splatting on              [27] M. Müller, B. Pross, OGC WPS 2.0 interface standard, Open Geosp. Consort. Inc.
     today’s GPUs, in: Proceedings Eurographics/IEEE VGTC Symposium Point-Based                         (2015).
     Graphics, 2005., 2005, pp. 17–141.                                                            [28] S. Nebiker, S. Bleisch, M. Christen, Rich point clouds in virtual globes–a new
 [4] C. Boucheny, Interactive scientiﬁc visualization of large datasets: towards a per-                 paradigm in city modeling? Comput. Environ. Urban Syst. 34 (6) (2010) 508–517.
     ceptive-based approach Ph.D. thesis, Ph.D. Dissertation, Université Joseph Fourier,           [29] S. Ostrowski, G. Jóÿków, C. Toth, B.V. Jagt, Analysis of point cloud generation from
     Grenoble, 2009.                                                                                    UAS images, ISPRS Ann. Photogramm. Remote Sens. Spat. Inform. Sci. 2 (1) (2014)
 [5] A. Boulch, B.L. Saux, N. Audebert, Unstructured point cloud semantic labeling using                45–51.
     deep segmentation networks, in: Eurographics Workshop on 3D Object Retrieval,                 [30] V. Pătrăucean, I. Armeni, M. Nahangi, J. Yeung, I. Brilakis, C. Haas, State of research
     volume 2, 2017, p. 1.                                                                              in automatic as-built modelling, Adv. Eng. Inf. 29 (2) (2015) 162–171.
 [6] H. Butler, D.C. Finnegan, P.J. Gadomski, U.K. Verma, plas. io: open source,                   [31] S. Peleg, M. Ben-Ezra, Y. Pritch, Omnistereo: panoramic stereo imaging, IEEE Trans.
     browser-based webGL point cloud visualization, AGU Fall Meeting Abstracts, 2014.                   Pattern Anal. Mach. Intell. 23 (3) (2001) 279–290.
 [7] D. Chen, R. Wang, J. Peethambaran, Topologically aware building rooftop recon-                [32] R. Pintus, E. Gobbetti, M. Agus, Real-time rendering of massive unstructured raw
     struction from airborne laser scanning point clouds, IEEE Trans. Geosci. Remote                    point clouds using screen-space operators, in: Proceedings of VAST 2011, 2011,
     Sens. 55 (12) (2017) 7032–7052.                                                                    pp. 105–112.
 [8] M. Christen, S. Nebiker, Visualisation of complex 3D city models on mobile web-               [33] F. Poux, P. Hallot, R. Neuville, R. Billen, Smart point cloud: Deﬁnition and remain-
     browsers using cloud-based image provisioning, ISPRS Ann. Photogramm. Remote                       ing challenges, ISPRS Ann. Photogramm. Remote Sens. Spat. Inform. Sci. 4 (2016)
     Sens. Spat. Inform. Sci. 2 (2015) 517–522.                                                         119–127.
 [9] R. Cura, J. Perret, N. Paparoditis, A scalable and multi-purpose point cloud server           [34] R. Preiner, S. Jeschke, M. Wimmer, Auto splats: Dynamic point cloud visualization
     (PCS) for easier and faster point cloud data management and processing, ISPRS J.                   on the GPU, in: Proceedings of the EGPGV, 2012, pp. 139–148.
     Photogramm. Remote Sens. 127 (2017) 39–56.                                                    [35] F. Remondino, M.G. Spera, E. Nocerino, F. Menna, F. Nex, S. Gonizzi-Barsanti, Dense
[10] D. Deibe, M. Amor, R. Doallo, Supporting multi-resolution out-of-core rendering of                 image matching: comparisons and analyses, in: Proceedings of DigitalHeritage 2013,
     massive liDAR point clouds through non-redundant data structures, Int. J. Geogr.                   volume 1, 2013, pp. 47–54.
     Informa. Sci. 33 (3) (2019) 593–617.                                                          [36] R. Richter, M. Behrens, J. Döllner, Object class segmentation of massive 3D point
[11] D. Deibe, M. Amor, R. Doallo, D. Miranda, M. Cordero, GVLiDAR: an interactive                      clouds of urban areas using point cloud topology, Int. J. Remote Sens. 34 (23) (2013)
     web-based visualization framework to support geospatial measures on lidar data,                    8408–8424.
     Int. J. Remote Sens. 38 (3) (2017) 827–849.                                                   [37] R. Richter, S. Discher, J. Döllner, Out-of-core visualization of classiﬁed 3d point
[12] J. Döllner, B. Hagedorn, J. Klimke, Server-based rendering of large 3d scenes for                  clouds, in: 3D Geoinformation Science, Springer, 2015, pp. 227–242.
     mobile devices using g-buﬀer cube maps, in: Proceedings of the 17th International             [38] R. Richter, J.E. Kyprianidis, J. Döllner, Out-of-core GPU-based change detection in
     Conference on 3D Web Technology, pp. 97–100.                                                       massive 3d point clouds, Transactions in GIS 17 (5) (2013) 724–741.
[13] J.U.H. Eitel, B. Höﬂe, L.A. Vierling, A. Abellán, G.P. Asner, J.S. Deems, C.L. Glen-          [39] M.B. Rodriguez, E. Gobbetti, F. Marton, R. Pintus, G. Pintore, A. Tinti, Interactive
     nie, P.C. Joerg, A.L. LeWinter, T.S. Magney, Beyond 3-D: the new spectrum of lidar                 exploration of gigantic point clouds on mobile devices, in: 13th International Con-
     applications for earth and ecological sciences, Remote Sens. Environ. 186 (2016)                   ference on Virtual Reality, Archaeology and Cultural Heritage, 2012, pp. 57–64.
     372–392.                                                                                      [40] S. Rusinkiewicz, M. Levoy, QSplat: a multiresolution point rendering system for large
[14] J. Elseberg, D. Borrmann, A. Nüchter, One billion points in the cloud–an octree for                meshes, in: Proceedings of the 27th annual conference on Computer graphics and
     eﬃcient processing of 3D laser scans, ISPRS J. Photogramm. Remote Sens. 76 (2013)                  interactive techniques, 2000, pp. 343–352.
     76–88.                                                                                        [41] H. Rüther, C. Held, R. Bhurtha, R. Schroeder, S. Wessels, From point cloud to tex-
[15] Z. Gao, L. Nocera, M. Wang, U. Neumann, Visualizing aerial liDAR cities with hierar-               tured model, the zamani laser scanning pipeline in heritage documentation, S. Afr.
     chical hybrid point-polygon structures, in: Proceedings of Graphics Interface, 2014,               J. Geomat. 1 (1) (2012) 44–59.
     pp. 137–144.                                                                                  [42] T. Saito, T. Takahashi, Comprehensible rendering of 3-D shapes, in: ACM SIGGRAPH
[16] S. García, R. Pagés, D. Berjón, F. Morán, Textured splat-based point clouds for ren-               Computer Graphics ACM, volume 24, 1990, pp. 197–206.
     dering in handheld devices, in: Proceedings of the 20th International Conference on           [43] C. Scheiblauer, M. Wimmer, Out-of-core selection and editing of huge point clouds,
     3D Web Technology, 2015, pp. 227–230.                                                              Comput. Gr. 35 (2) (2011) 342–351.
[17] P. Goswami, F. Erol, R. Mukhi, R. Pajarola, E. Gobbetti, An eﬃcient multi-resolu-             [44] M. Schütz, M. Wimmer, High-quality point-based rendering using fast single-pass
     tion framework for high quality interactive rendering of massive point clouds using                interpolation, in: Proceedings of Digital Heritage 2015, 2015, pp. 369–372.
     multi-way kd-trees, Vis. Comput. 29 (1) (2013) 69–83.                                         [45] M. Schütz, M. Wimmer, Rendering large point clouds in web browsers, Proc. CESCG
[18] M. Gross, H. Pﬁster, Point-Based Graphics, Morgan Kaufmann, 2011.                                  (2015) 83–90.
[19] R. Gutbell, L. Pandikow, V. Coors, Y. Kammeyer, A framework for server side ren-              [46] L. Simons, S. He, P. Tittman, N. Amenta, Point-based rendering of forest liDAR, in:
     dering using OGC’s 3D portrayal service, in: Proceedings of the 21st International                 Workshop on Visualisation in Environmental Sciences (EnvirVis), The Eurographics
     Conference on Web3D Technology, 2016, pp. 137–146.                                                 Association, 2014, pp. 19–23.
[20] B. Hagedorn, S. Thum, T. Reitz, V. Coors, R. Gutbell, OGC 3D portrayal service 1.0,           [47] T.-A. Teo, C.-M. Chiu, Pole-like road object detection from mobile lidar system using
     OGC Implementation Standard 1.0., 2017. Open Geospatial Consortium.                                a coarse-to-ﬁne approach, IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 8 (10)
[21] J. Huang, S. You, Point cloud labeling using 3D convolutional neural network, in:                  (2015) 4805–4818.
     Proceedings of the 23rd International Conference on Pattern Recognition, 2016,                [48] P. van Oosterom, O. Martinez-Rubi, T. Tijssen, R. Gonçalves, Realistic benchmarks
     pp. 2670–2675.                                                                                     for point cloud data management systems, in: Advances in 3D Geoinformation,
[22] A. Jochem, B. Höﬂe, V. Wichmann, M. Rutzinger, A. Zipf, Area-wide roof plane                       Springer, 2017, pp. 1–30.
     segmentation in airborne liDAR point clouds, Comput Environ Urban Syst 36 (1)                 [49] M. Wand, A. Berner, M. Bokeloh, P. Jenke, A. Fleck, M. Hoﬀmann, B. Maier,
     (2012) 54–64.                                                                                      D. Staneker, A. Schilling, H.-P. Seidel, Processing and interactive editing of huge
[23] T.P. Kersten, H.-J. Przybilla, M. Lindstaedt, F. Tschirschwitz, M. Misgaiski-Hass,                 point clouds from 3D scanners, Comput. Gr. 32 (2) (2008) 204–220.
     Comparative geometrical investigations of hand-held scanning systems, ISPRS Ann.              [50] L. Zhang, Q. Sun, Y. He, Splatting lines: an eﬃcient method for illustrating 3d sur-
     Photogramm. Remote Sens. Spat. Inform. Sci. (2016).                                                faces and volumes, in: Proceedings of the 18th meeting of the ACM SIGGRAPH Sym-
                                                                                                        posium on Interactive 3D Graphics and Games, 2014, pp. 135–142.
